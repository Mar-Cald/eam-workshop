---
title: " "
---

```{r}
#| echo: false
#| message: false
library(ggplot2)
library(dplyr)
```

## Bayesian Inference

**Data are fixed**, but **parameters are uncertain**.

<br/>
**Bayes’ Rule**:
<br/>

$$
\text{Posterior} \propto \text{Likelihood} \times \text{Prior}
$$
<br/>

- Inference produces **posterior distributions** over parameters  

- Captures uncertainty and incorporates prior knowledge  


## Hierarchical Modeling {.align-center}

*Are participants identical or fully independent?*

:::: {.columns}
::: {.column width="45%"}

Models **group-level structure**

each participant’s parameters ∼ drawn from a population distribution
<br/><br/>

**Group-level** generalization
<br/>

**Individual-level** inference  
<br/>

:::

::: {.column width="55%"}


```{r}
#| echo: false
#| fig-width: 8
#| fig-asp: .7
#| message: false
#| warning: false

# Function to create a normal distribution curve
normal_curve <- function(mean, sd, n = 200, range_mult = 3) {
  x <- seq(mean - range_mult*sd, mean + range_mult*sd, length.out = n)
  y <- dnorm(x, mean, sd)
  data.frame(x = x, y = y)
}

# Create data for the plots
hyper_curve <- normal_curve(0.5, 0.05)
individual_curves <- rbind(
  normal_curve(0.35, 0.06) %>% mutate(subj = "1"),
  normal_curve(0.5, 0.03) %>% mutate(subj = "2"),
  normal_curve(0.7, 0.04) %>% mutate(subj = "3")
)

# Normalize y values
max_y <- max(c(hyper_curve$y, individual_curves$y))
hyper_curve$y <- hyper_curve$y / max_y
individual_curves$y <- individual_curves$y / max_y

# Create the main plot
p1 <- ggplot() +
  # Hyper-distribution curve
  geom_line(data = hyper_curve, aes(x, y + 1.6), size = 2.5, color = "black") +
  # Individual curves
  geom_line(data = individual_curves, aes(x, y - .1, 
                                          group = subj, color = subj,
                                          fill = subj), 
            size = 2.5, show.legend = FALSE) +  # X marks
  geom_point(aes(x = c(0.38, 0.5, 0.65), y = rep(1.12, 3)), 
             shape = 21, size = 8, fill = c("cyan4", "green2", "purple2")) +
  # Labels
  annotate("text", x = 0.5, y = 1.8, label = "μ,σ", color = "red", size = 10) +
  # Customize the plot
  theme_void() +
  coord_cartesian(xlim = c(0.1, 0.9), ylim = c(-0.2, 2.3), expand = FALSE) +
  # Add arrows top-down
  geom_segment(aes(x = 0.45, y = 1.6, xend = 0.39, yend = 1.2), size = 1.5,
               arrow = arrow(length = unit(0.2, "cm")), color = "gray50") +
  geom_segment(aes(x = 0.5, y = 1.6, xend = 0.5, yend = 1.2), size = 1.5,
               arrow = arrow(length = unit(0.2, "cm")), color = "gray50") +
  geom_segment(aes(x = 0.55, y = 1.6, xend = 0.64, yend = 1.2), size = 1.5,
               arrow = arrow(length = unit(0.2, "cm")), color = "gray50") +
  # Add arrows bottom-up
  geom_segment(aes(x = 0.35, y = 0.7, xend = 0.37, yend = 1.02), size = 1,
               arrow = arrow(length = unit(0.2, "cm")), color = "gray50") +
  geom_segment(aes(x = 0.5, y = 0.95, xend = 0.5, yend = 1.02), size = 1,
               arrow = arrow(length = unit(0.2, "cm")), color = "gray50") +
  geom_segment(aes(x = 0.69, y = 0.8, xend = 0.66, yend = 1.02), size = 1,
               arrow = arrow(length = unit(0.2, "cm")), color = "gray50") +
  scale_color_manual(values = c("1" = "cyan4", "2" = "green2", "3" = "purple2"))+
  geom_point(aes(x = c(0.35, 0.5, 0.7), y = rep(-0.1, 3)), 
             shape = 21, size = 8, fill = c("cyan4", "green2", "purple2"))


# Display the plot
print(p1)


```
:::
:::::


## Why Hierarchical Models?

-   Reduces bias from unmodeled individual variability  
-   Prevents overfitting *and* underfitting  
-   **Shrinkage**: pulls extreme or low-quality estimates toward the group mean  

> [Boehm et al. (2018), *Behavior Research Methods*](https://doi.org/10.3758/s13428-018-1054-3)



## What Are We Trying to Infer?

We want to estimate:

- **Individual-level parameters**:  $\alpha_1, \alpha_2, \dots, \alpha_N$


- **Group-level structure**:  
  A shared population distribution  $\alpha_i \sim \mathcal{N}(\mu, \Sigma)$

This enables both **individual** and **population** inference.


## Model Structure

The hierarchical model defines a **joint posterior** over all unknowns:

$$
p(\alpha_i, \mu, \Sigma \mid \text{data}) \propto 
p(\text{data} \mid \alpha_i) \cdot 
p(\alpha_i \mid \mu, \Sigma) \cdot 
p(\mu, \Sigma)
$$

- **Likelihood**:  
  $p(\text{data} \mid \alpha_i)$  
  — How well each participant's data is explained by their parameters

- **Group-level model**:  
  $p(\alpha_i \mid \mu, \Sigma)$  — Individual parameters drawn from population distribution

- **Hyperprior**:  
  $p(\mu, \Sigma)$  — Prior beliefs over the group-level structure


## Group-Level Parameters

Let $n$ = number of individual parameters per subject:

- $\mu$: vector of **population means**  
- $\Sigma$: symmetric **covariance matrix**, including:

  - Diagonal: **Variances** ($\sigma^2$)
  - Off-diagonal: **Covariances**  
    $\frac{n(n-1)}{2}$ elements total

These hyperparameters are **learned from the data**.

## Priors

Cognitive-model parameters must be transformed to have support on the real line. This transformation is necessary to meet the assumption of the normal group-level distribution. 

-   **Log** transform: Applied to parameters with a lower bound (e.g., non-decision time, which cannot be negative)
-   **Probit** transform: Applied to parameters with both lower and upper bounds (e.g., the starting point parameter in the Drift Diffusion Model, which must lie between two response boundaries)

As a result, priors are specified on these transformed parameters rather than on the original scales.

## Set up - EMC2

```{r, echo=TRUE}
# # If not already done, install the EMC2 package
# remotes::install_github("ampl-psych/EMC2",ref="dev")
library(EMC2)
```

## Design specification

The design function creates a design object that maps model parameters to experimental conditions using linear model formulas. This object specifies:

1.  Model type
2.  Linear models for estimated parameter types (default values are used for omitted types)
3.  Parameters to be fixed as constants (optional)
4.  Functions for creating custom factors (optional)
5.  Custom contrast coding for factors (optional)


The simulation procedure

